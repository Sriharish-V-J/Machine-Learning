{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import wfdb\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ---------------------------\n",
    "# Data Loading & Preprocessing\n",
    "# ---------------------------\n",
    "def load_ecg_data(base_dir, fixed_length=1000):\n",
    "    X, y = [], []\n",
    "    \n",
    "    # Iterate through each patient folder\n",
    "    for patient in os.listdir(base_dir):\n",
    "        patient_path = os.path.join(base_dir, patient)\n",
    "        if not os.path.isdir(patient_path):\n",
    "            continue\n",
    "        \n",
    "        # Process each .dat file in the patient folder\n",
    "        for file in os.listdir(patient_path):\n",
    "            if file.endswith('.dat'):\n",
    "                file_prefix = file.split('.')[0]\n",
    "                file_path = os.path.join(patient_path, file_prefix)\n",
    "                \n",
    "                # Read ECG signal using WFDB\n",
    "                try:\n",
    "                    signals, fields = wfdb.rdsamp(file_path)\n",
    "                except:\n",
    "                    print(f\"Skipping corrupt/invalid file: {file_path}\")\n",
    "                    continue\n",
    "                \n",
    "                # Use the first lead (modify if multi-lead needed)\n",
    "                ecg_signal = signals[:, 0]\n",
    "                \n",
    "                # Normalize signal to [0, 1]\n",
    "                ecg_normalized = (ecg_signal - np.min(ecg_signal)) / (np.max(ecg_signal) - np.min(ecg_signal))\n",
    "                \n",
    "                # Pad/Truncate to fixed length\n",
    "                if len(ecg_normalized) > fixed_length:\n",
    "                    ecg_processed = ecg_normalized[:fixed_length]\n",
    "                else:\n",
    "                    ecg_processed = np.pad(ecg_normalized, (0, fixed_length - len(ecg_normalized)), mode='constant')\n",
    "                \n",
    "                X.append(ecg_processed)\n",
    "                y.append(1 if 'lre' in file else 0)  # Label based on filename\n",
    "    \n",
    "    # Convert to numpy arrays and reshape for LSTM\n",
    "    X = np.array(X).reshape(-1, fixed_length, 1)\n",
    "    y = np.array(y)\n",
    "    return X, y\n",
    "\n",
    "# Load data\n",
    "BASE_DIR = 'path/to/patient_folders'  # Update this path\n",
    "X_ecg, y_ecg = load_ecg_data(BASE_DIR)\n",
    "\n",
    "# Split data into train/test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_ecg, y_ecg, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# ---------------------------\n",
    "# LSTM Model Architecture\n",
    "# ---------------------------\n",
    "model = Sequential([\n",
    "    LSTM(64, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    Dropout(0.5),\n",
    "    LSTM(32),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# ---------------------------\n",
    "# Training & Evaluation\n",
    "# ---------------------------\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stop]\n",
    ")\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM - Torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [1] Install Required Libraries\n",
    "!pip install wfdb torch torchvision torchaudio sklearn\n",
    "\n",
    "# %% [2] Imports\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import wfdb\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# %% [3] Configuration\n",
    "config = {\n",
    "    \"data_dir\": \"ptb-diagnostic-ecg-database-1.0.0\",\n",
    "    \"batch_size\": 32,\n",
    "    \"max_seq_length\": 5000,  # 5 seconds at 1000 Hz\n",
    "    \"hidden_size\": 128,\n",
    "    \"num_layers\": 2,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"num_epochs\": 15,\n",
    "    \"num_classes\": 15  # Update based on your actual class count\n",
    "}\n",
    "\n",
    "# %% [4] Data Loading and Preprocessing\n",
    "def load_ecg_data(data_dir):\n",
    "    records = [f.split('.')[0] for f in os.listdir(data_dir) if f.endswith('.hea')]\n",
    "    signals = []\n",
    "    labels = []\n",
    "    \n",
    "    for record in records:\n",
    "        # Load signal\n",
    "        signal, _ = wfdb.rdsamp(os.path.join(data_dir, record))\n",
    "        # Load header information\n",
    "        header = wfdb.rdheader(os.path.join(data_dir, record))\n",
    "        \n",
    "        # Preprocess signal\n",
    "        signal = signal[:, :15]  # Select first 15 channels\n",
    "        signal = signal[::4, :]  # Downsample to 250 Hz\n",
    "        signals.append(signal)\n",
    "        \n",
    "        # Extract label from comments\n",
    "        diagnosis = next((c.split(': ')[1] for c in header.comments if c.startswith('# Diagnosis')), 'Unknown')\n",
    "        labels.append(diagnosis)\n",
    "    \n",
    "    return signals, labels\n",
    "\n",
    "# Load raw data\n",
    "signals, labels = load_ecg_data(config[\"data_dir\"])\n",
    "\n",
    "# %% [5] Label Encoding\n",
    "le = LabelEncoder()\n",
    "encoded_labels = le.fit_transform(labels)\n",
    "config[\"num_classes\"] = len(le.classes_)\n",
    "print(f\"Class mapping: {dict(zip(le.classes_, le.transform(le.classes_)))}\")\n",
    "\n",
    "# %% [6] Dataset Class\n",
    "class ECGDataset(Dataset):\n",
    "    def __init__(self, signals, labels, max_len):\n",
    "        self.signals = signals\n",
    "        self.labels = labels\n",
    "        self.max_len = max_len\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.signals)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        signal = self.signals[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # Truncate or pad sequence\n",
    "        if signal.shape[0] > self.max_len:\n",
    "            signal = signal[:self.max_len, :]\n",
    "        else:\n",
    "            pad_len = self.max_len - signal.shape[0]\n",
    "            signal = np.pad(signal, ((0, pad_len), (0, 0)), 'constant')\n",
    "            \n",
    "        return torch.FloatTensor(signal), torch.LongTensor([label])\n",
    "\n",
    "# %% [7] Data Splitting and Loaders\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    signals, encoded_labels, \n",
    "    test_size=0.2, \n",
    "    stratify=encoded_labels,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "train_dataset = ECGDataset(X_train, y_train, config[\"max_seq_length\"])\n",
    "test_dataset = ECGDataset(X_test, y_test, config[\"max_seq_length\"])\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=config[\"batch_size\"],\n",
    "    shuffle=True,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=config[\"batch_size\"],\n",
    "    shuffle=False,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "# %% [8] LSTM Model Architecture\n",
    "class ECG_LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=True\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_size*2, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(64, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)  # (batch_size, seq_len, hidden_size*2)\n",
    "        out = out[:, -1, :]     # Take last timestep output\n",
    "        return self.classifier(out)\n",
    "\n",
    "# %% [9] Initialize Model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = ECG_LSTM(\n",
    "    input_size=15,\n",
    "    hidden_size=config[\"hidden_size\"],\n",
    "    num_layers=config[\"num_layers\"],\n",
    "    num_classes=config[\"num_classes\"]\n",
    ").to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=config[\"learning_rate\"])\n",
    "\n",
    "# %% [10] Training Loop\n",
    "def train_model(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for inputs, labels in dataloader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.squeeze().to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "    return running_loss/total, correct/total\n",
    "\n",
    "# %% [11] Evaluation Loop\n",
    "def evaluate_model(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.squeeze().to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            \n",
    "    return running_loss/total, correct/total, all_preds, all_labels\n",
    "\n",
    "# %% [12] Training Execution\n",
    "best_acc = 0.0\n",
    "for epoch in range(config[\"num_epochs\"]):\n",
    "    train_loss, train_acc = train_model(model, train_loader, criterion, optimizer, device)\n",
    "    test_loss, test_acc, _, _ = evaluate_model(model, test_loader, criterion, device)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{config['num_epochs']}\")\n",
    "    print(f\"Train Loss: {train_loss:.4f} | Acc: {train_acc:.4f}\")\n",
    "    print(f\"Test Loss: {test_loss:.4f} | Acc: {test_acc:.4f}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    if test_acc > best_acc:\n",
    "        best_acc = test_acc\n",
    "        torch.save(model.state_dict(), \"best_model.pth\")\n",
    "\n",
    "# %% [13] Final Evaluation\n",
    "model.load_state_dict(torch.load(\"best_model.pth\"))\n",
    "_, test_acc, preds, labels = evaluate_model(model, test_loader, criterion, device)\n",
    "print(classification_report(labels, preds, target_names=le.classes_))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
