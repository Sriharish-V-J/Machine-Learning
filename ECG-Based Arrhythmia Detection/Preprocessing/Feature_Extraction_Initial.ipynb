{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting neurokit2\n",
      "  Downloading neurokit2-0.2.10-py2.py3-none-any.whl.metadata (37 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\rajit\\anaconda3\\envs\\ml_env\\lib\\site-packages (from neurokit2) (2.32.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\rajit\\anaconda3\\envs\\ml_env\\lib\\site-packages (from neurokit2) (2.2.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\rajit\\anaconda3\\envs\\ml_env\\lib\\site-packages (from neurokit2) (2.2.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\rajit\\anaconda3\\envs\\ml_env\\lib\\site-packages (from neurokit2) (1.15.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.0 in c:\\users\\rajit\\anaconda3\\envs\\ml_env\\lib\\site-packages (from neurokit2) (1.6.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\rajit\\anaconda3\\envs\\ml_env\\lib\\site-packages (from neurokit2) (3.10.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\rajit\\anaconda3\\envs\\ml_env\\lib\\site-packages (from scikit-learn>=1.0.0->neurokit2) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\rajit\\anaconda3\\envs\\ml_env\\lib\\site-packages (from scikit-learn>=1.0.0->neurokit2) (3.5.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\rajit\\anaconda3\\envs\\ml_env\\lib\\site-packages (from matplotlib->neurokit2) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\rajit\\anaconda3\\envs\\ml_env\\lib\\site-packages (from matplotlib->neurokit2) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\rajit\\anaconda3\\envs\\ml_env\\lib\\site-packages (from matplotlib->neurokit2) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\rajit\\anaconda3\\envs\\ml_env\\lib\\site-packages (from matplotlib->neurokit2) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\rajit\\anaconda3\\envs\\ml_env\\lib\\site-packages (from matplotlib->neurokit2) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\rajit\\anaconda3\\envs\\ml_env\\lib\\site-packages (from matplotlib->neurokit2) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\rajit\\anaconda3\\envs\\ml_env\\lib\\site-packages (from matplotlib->neurokit2) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\rajit\\anaconda3\\envs\\ml_env\\lib\\site-packages (from matplotlib->neurokit2) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\rajit\\anaconda3\\envs\\ml_env\\lib\\site-packages (from pandas->neurokit2) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\rajit\\anaconda3\\envs\\ml_env\\lib\\site-packages (from pandas->neurokit2) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rajit\\anaconda3\\envs\\ml_env\\lib\\site-packages (from requests->neurokit2) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rajit\\anaconda3\\envs\\ml_env\\lib\\site-packages (from requests->neurokit2) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rajit\\anaconda3\\envs\\ml_env\\lib\\site-packages (from requests->neurokit2) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rajit\\anaconda3\\envs\\ml_env\\lib\\site-packages (from requests->neurokit2) (2025.1.31)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\rajit\\anaconda3\\envs\\ml_env\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->neurokit2) (1.16.0)\n",
      "Downloading neurokit2-0.2.10-py2.py3-none-any.whl (693 kB)\n",
      "   ---------------------------------------- 0.0/693.1 kB ? eta -:--:--\n",
      "   ------------------------------ --------- 524.3/693.1 kB 5.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 693.1/693.1 kB 1.6 MB/s eta 0:00:00\n",
      "Installing collected packages: neurokit2\n",
      "Successfully installed neurokit2-0.2.10\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install neurokit2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wfdb\n",
      "  Downloading wfdb-4.2.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: matplotlib>=3.2.2 in c:\\users\\rajit\\anaconda3\\envs\\ml_env\\lib\\site-packages (from wfdb) (3.10.0)\n",
      "Requirement already satisfied: numpy>=1.26.4 in c:\\users\\rajit\\anaconda3\\envs\\ml_env\\lib\\site-packages (from wfdb) (2.2.2)\n",
      "Requirement already satisfied: pandas>=2.2.3 in c:\\users\\rajit\\anaconda3\\envs\\ml_env\\lib\\site-packages (from wfdb) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.8.1 in c:\\users\\rajit\\anaconda3\\envs\\ml_env\\lib\\site-packages (from wfdb) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.13.0 in c:\\users\\rajit\\anaconda3\\envs\\ml_env\\lib\\site-packages (from wfdb) (1.15.1)\n",
      "Collecting soundfile>=0.10.0 (from wfdb)\n",
      "  Downloading soundfile-0.13.1-py2.py3-none-win_amd64.whl.metadata (16 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\rajit\\anaconda3\\envs\\ml_env\\lib\\site-packages (from matplotlib>=3.2.2->wfdb) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\rajit\\anaconda3\\envs\\ml_env\\lib\\site-packages (from matplotlib>=3.2.2->wfdb) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\rajit\\anaconda3\\envs\\ml_env\\lib\\site-packages (from matplotlib>=3.2.2->wfdb) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\rajit\\anaconda3\\envs\\ml_env\\lib\\site-packages (from matplotlib>=3.2.2->wfdb) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\rajit\\anaconda3\\envs\\ml_env\\lib\\site-packages (from matplotlib>=3.2.2->wfdb) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\rajit\\anaconda3\\envs\\ml_env\\lib\\site-packages (from matplotlib>=3.2.2->wfdb) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\rajit\\anaconda3\\envs\\ml_env\\lib\\site-packages (from matplotlib>=3.2.2->wfdb) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\rajit\\anaconda3\\envs\\ml_env\\lib\\site-packages (from matplotlib>=3.2.2->wfdb) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\rajit\\anaconda3\\envs\\ml_env\\lib\\site-packages (from pandas>=2.2.3->wfdb) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\rajit\\anaconda3\\envs\\ml_env\\lib\\site-packages (from pandas>=2.2.3->wfdb) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rajit\\anaconda3\\envs\\ml_env\\lib\\site-packages (from requests>=2.8.1->wfdb) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rajit\\anaconda3\\envs\\ml_env\\lib\\site-packages (from requests>=2.8.1->wfdb) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rajit\\anaconda3\\envs\\ml_env\\lib\\site-packages (from requests>=2.8.1->wfdb) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rajit\\anaconda3\\envs\\ml_env\\lib\\site-packages (from requests>=2.8.1->wfdb) (2025.1.31)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\rajit\\anaconda3\\envs\\ml_env\\lib\\site-packages (from soundfile>=0.10.0->wfdb) (1.17.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\rajit\\anaconda3\\envs\\ml_env\\lib\\site-packages (from cffi>=1.0->soundfile>=0.10.0->wfdb) (2.21)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\rajit\\anaconda3\\envs\\ml_env\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.2.2->wfdb) (1.16.0)\n",
      "Downloading wfdb-4.2.0-py3-none-any.whl (162 kB)\n",
      "Downloading soundfile-0.13.1-py2.py3-none-win_amd64.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.0/1.0 MB 9.7 MB/s eta 0:00:00\n",
      "Installing collected packages: soundfile, wfdb\n",
      "Successfully installed soundfile-0.13.1 wfdb-4.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install wfdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import neurokit2 as nk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import wfdb\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define your Dataset and output path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Paths\n",
    "base_path = 'D:\\\\Machine learning project\\\\ptb-diagnostic-ecg-database-1.0.0'  # Replace with your dataset path\n",
    "output_path = './ECG_Processed.csv'  # Output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Empty DataFrame\n",
    "features_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Processing Patient Folders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Process Patients\n",
    "for patient_folder in sorted(os.listdir(base_path)):\n",
    "    patient_path = os.path.join(base_path, patient_folder)\n",
    "\n",
    "    if os.path.isdir(patient_path):\n",
    "        # Identify .dat and .hea files\n",
    "        dat_file = []\n",
    "        hea_file = []\n",
    "        xyz_files = []\n",
    "        for file in os.listdir(patient_path):\n",
    "            if file.endswith('.dat'):\n",
    "                dat_file.append(os.path.join(patient_path, file))\n",
    "                #print(f'dat_file : {dat_file}')\n",
    "            elif file.endswith('.hea'):\n",
    "                hea_file.append(os.path.join(patient_path, file))\n",
    "                #print(f'hea_file : {hea_file}')\n",
    "            elif file.endswith('.xyz'):\n",
    "                xyz_files.append(os.path.join(patient_path, file))\n",
    "                #print(f'xyz_files : {xyz_files}')\n",
    "\n",
    "        for i in range(len(dat_file)):\n",
    "            if dat_file and hea_file:   \n",
    "                try:\n",
    "                    if hea_file[i]:\n",
    "                        hea_content = open(hea_file[i], 'r').read()\n",
    "                        with open(hea_file[i], 'r') as file:\n",
    "                            first_line = file.readline().strip()\n",
    "                        # Regular expression patterns to extract the required attributes\n",
    "                        patterns = {\n",
    "                            # Extract only the first part (ID) before any space\n",
    "                            \"age\": r\"# age:\\s*(\\d+)\",\n",
    "                            \"sex\": r\"# sex:\\s*(\\w+)\",\n",
    "                            \"Reason for admission\": r\"# Reason for admission:\\s*(.*)\",\n",
    "                            \"Acute infarction (localization)\": r\"# Acute infarction \\(localization\\):\\s*(.*)\",\n",
    "                            \"Smoker\": r\"# Smoker:\\s*(\\w+)\",\n",
    "                        }\n",
    "\n",
    "                        # Extract the values based on the patterns\n",
    "                        extracted_data = {}\n",
    "                        extracted_data[\"Pat_ID\"] = patient_folder\n",
    "                        extracted_data[\"ID\"] = first_line.split()[0]\n",
    "                        for key, pattern in patterns.items():\n",
    "                            match = re.search(pattern, hea_content)\n",
    "                            if match:\n",
    "                                extracted_data[key] = match.group(1)\n",
    "                        \n",
    "                            else:\n",
    "                                extracted_data[key] = \"NA\"\n",
    "\n",
    "                        #features_df = pd.concat([features_df, pd.DataFrame(extracted_data, index=[0])], ignore_index=False)\n",
    "\n",
    "                    record = wfdb.rdrecord(dat_file[i][:-4])  # Strip .dat extension\n",
    "                    print(dat_file[i][:-4])\n",
    "                    sampling_rate = record.fs\n",
    "                    leads = record.sig_name  # List of leads\n",
    "                    # Assuming you have your ECG data in a NumPy array called 'ecg_signal'\n",
    "                    Lead_val = []\n",
    "                    for lead_index, lead_name in enumerate(leads[:3]):\n",
    "                        ecg_signal = record.p_signal[:, lead_index]  # Choose the first lead (index 0)\n",
    "\n",
    "                        # Get the sampling rate \n",
    "                        sampling_rate = record.fs\n",
    "\n",
    "                        # Preprocess ECG signal\n",
    "                        signals, info = nk.ecg_process(ecg_signal, sampling_rate=sampling_rate)\n",
    "\n",
    "                        # Example data\n",
    "                        # If ECG_R_Peaks is a binary array\n",
    "                        ECG_R_Peaks = np.array(signals['ECG_R_Peaks']) if 'ECG_R_Peaks' in signals else 0\n",
    "                        fs = 1000  # Sampling rate (Hz)\n",
    "\n",
    "                        # Step 1: Extract R-peak indices (if binary array)\n",
    "                        R_peak_indices = np.where(ECG_R_Peaks == 1)[0] if 'ECG_R_Peaks' in signals else 0\n",
    "\n",
    "                        # Step 2: Convert indices to timestamps (seconds)\n",
    "                        R_peak_timestamps = R_peak_indices / fs\n",
    "\n",
    "                        # Step 3: Calculate RR intervals (time difference between consecutive R-peaks)\n",
    "                        RR_intervals = np.diff(R_peak_timestamps) if 'ECG_R_Peaks' in signals else 0\n",
    "\n",
    "                        # Step 1: Extract indices of P onsets and R peaks (if binary arrays)\n",
    "                        ECG_P_Onset = np.array(signals['ECG_P_Onsets'])\n",
    "\n",
    "                        P_onset_indices = np.where(ECG_P_Onset == 1)[0]\n",
    "\n",
    "                        # Step 2: Convert indices to timestamps (seconds)\n",
    "                        P_onset_timestamps = P_onset_indices / fs\n",
    "                        R_peak_timestamps = R_peak_indices / fs\n",
    "\n",
    "                        # Step 3: Match each P onset to the nearest succeeding R peak\n",
    "                        PR_intervals = []\n",
    "                        for t_p in P_onset_timestamps:\n",
    "                            # Find the closest succeeding R peak\n",
    "                            succeeding_R_peaks = R_peak_timestamps[R_peak_timestamps > t_p]\n",
    "                            if len(succeeding_R_peaks) > 0:\n",
    "                                t_r = succeeding_R_peaks[0]  # Get the first (nearest) succeeding R peak\n",
    "                                PR_intervals.append(t_r - t_p)\n",
    "\n",
    "                        # Convert to numpy array for further processing\n",
    "                        PR_intervals = np.array(PR_intervals)\n",
    "\n",
    "                        ECG_Q_Peaks = np.array(signals['ECG_Q_Peaks'])\n",
    "                        ECG_T_Offsets = np.array(signals['ECG_T_Offsets'])\n",
    "\n",
    "                        # Step 1: Extract indices of Q peaks and T offsets (if binary arrays)\n",
    "                        Q_peak_indices = np.where(ECG_Q_Peaks == 1)[0]\n",
    "                        T_offset_indices = np.where(ECG_T_Offsets == 1)[0]\n",
    "\n",
    "                        # Step 2: Convert indices to timestamps (seconds)\n",
    "                        Q_peak_timestamps = Q_peak_indices / fs\n",
    "                        T_offset_timestamps = T_offset_indices / fs\n",
    "\n",
    "                        # Step 3: Match each Q peak to the nearest succeeding T offset\n",
    "                        QT_intervals = []\n",
    "                        for t_q in Q_peak_timestamps:\n",
    "                            # Find the closest succeeding T offset\n",
    "                            succeeding_T_offsets = T_offset_timestamps[T_offset_timestamps > t_q]\n",
    "                            if len(succeeding_T_offsets) > 0:\n",
    "                                t_t_offset = succeeding_T_offsets[0]  # Get the first (nearest) succeeding T offset\n",
    "                                QT_intervals.append(t_t_offset - t_q)\n",
    "\n",
    "                        # Convert to numpy array for further processing\n",
    "                        QT_intervals = np.array(QT_intervals)\n",
    "\n",
    "                        ECG_S_Peaks = np.array(signals['ECG_S_Peaks'])\n",
    "\n",
    "                        # Assuming you have the R-peaks detected\n",
    "                        R_peak_indices = np.where(signals['ECG_R_Peaks'] == 1)[0] if 'ECG_R_Peaks' in signals else 0 # Extract indices of R-peaks\n",
    "\n",
    "                        # Compute HRV metrics using the detected R-peaks\n",
    "                        hrv_metrics = nk.hrv_time(R_peak_indices, sampling_rate=1000)\n",
    "\n",
    "\n",
    "                        ECG_P_peaks = signals['ECG_P_Peaks']\n",
    "                        pp_intervals = np.diff(ECG_P_peaks)  # Convert to seconds\n",
    "\n",
    "                        s_peaks = signals['ECG_S_Peaks']\n",
    "                        t_onsets = signals['ECG_T_Onsets']\n",
    "\n",
    "                        # Calculate ST segment durations\n",
    "                        st_segments = np.array((t_onsets - s_peaks))/1000  # Convert to seconds\n",
    "\n",
    "                        # Extract the onsets and offsets of R-peaks\n",
    "                        r_onsets = signals['ECG_R_Onsets'].dropna().values\n",
    "                        r_offsets = signals['ECG_R_Offsets'].dropna().values\n",
    "\n",
    "                        # Ensure matching lengths\n",
    "                        if len(r_onsets) != len(r_offsets):\n",
    "                            raise ValueError(\"Mismatched lengths between R onsets and offsets.\")\n",
    "\n",
    "                        # Calculate QRS intervals (difference between offsets and onsets)\n",
    "                        qrs_intervals = (r_offsets - r_onsets) / fs\n",
    "                        features = {\n",
    "                            f\"{lead_name}_Mean_ECG_Rate\": np.nanmean(signals['ECG_Rate']),\n",
    "                            f\"{lead_name}_Mean_ECG_Quality\": 0 if 'ECG_Quality' not in signals else np.nanmean(np.array(signals['ECG_Quality'])),\n",
    "                            f\"{lead_name}_Coeff_R_peaks\": 0 if 'ECG_R_Peaks' not in signals else np.nanstd(ECG_R_Peaks) / np.nanmean(ECG_R_Peaks),\n",
    "                            #f\"{lead_name}_Coeff_P_peaks\": 0 if np.isnan(np.nanstd(ECG_P_peaks) / np.nanmean(ECG_P_peaks)) else np.nanstd(ECG_P_peaks) / np.nanmean(ECG_P_peaks),\n",
    "                            #f\"{lead_name}_Coeff_Q_peaks\": 0 if np.isnan(np.nanstd(ECG_Q_Peaks) / np.nanmean(ECG_Q_Peaks)) else np.nanstd(ECG_Q_Peaks) / np.nanmean(ECG_Q_Peaks),\n",
    "                            #f\"{lead_name}_Coeff_S_peaks\": 0 if np.isnan(np.nanstd(ECG_S_Peaks) / np.nanmean(ECG_S_Peaks)) else np.nanstd(ECG_S_Peaks) / np.nanmean(ECG_S_Peaks),\n",
    "                            #f\"{lead_name}_Coeff_T_peaks\": 0 if np.any(np.isnan(signals['ECG_T_Peaks'])) else np.nanstd(signals['ECG_T_Peaks']) / np.nanmean(signals['ECG_T_Peaks']),\n",
    "                            f\"{lead_name}_Mean_ECG_Phase_Atrial\": np.nanmean(signals['ECG_Phase_Atrial']),\n",
    "                            f\"{lead_name}_Mean_ECG_Phase_Completion_Atrial\": np.nanmean(signals['ECG_Phase_Completion_Atrial']),\n",
    "                            f\"{lead_name}_Mean_ECG_Phase_Ventricular\": np.nanmean(signals['ECG_Phase_Ventricular']),\n",
    "                            f\"{lead_name}_Mean_ECG_Phase_Completion_Ventricular\": np.nanmean(signals['ECG_Phase_Completion_Ventricular']),\n",
    "                            f\"{lead_name}_Coeff_RR_intervals\": 0 if np.isnan(np.nanstd(RR_intervals) / np.nanmean(RR_intervals)) else np.nanstd(RR_intervals) / np.nanmean(RR_intervals),\n",
    "                            f\"{lead_name}_Coeff_PR_intervals\": 0 if np.isnan(np.nanstd(PR_intervals) / np.nanmean(PR_intervals)) else np.nanstd(PR_intervals) / np.nanmean(PR_intervals),\n",
    "                            f\"{lead_name}_Coeff_QT_intervals\": 0 if np.isnan(np.mean(QT_intervals)) else np.nanstd(QT_intervals) / np.nanmean(QT_intervals),\n",
    "                            f\"{lead_name}_std_pp_intervals\": 0 if np.isnan(np.nanstd(pp_intervals)) else np.nanstd(pp_intervals),\n",
    "                            f\"{lead_name}_std_QRS_Interval\": 0 if np.isnan(np.nanstd(qrs_intervals)) else np.nanstd(qrs_intervals),\n",
    "                            f\"{lead_name}_HRV_SDNN\": 0 if np.isnan(hrv_metrics['HRV_SDNN'].values[0]) else hrv_metrics['HRV_SDNN'].values[0],\n",
    "                            f\"{lead_name}_HRV_RMSSD\": 0 if np.isnan(hrv_metrics['HRV_RMSSD'].values[0]) else hrv_metrics['HRV_RMSSD'].values[0],\n",
    "                            f\"{lead_name}_HRV_pNN20\": 0 if np.isnan(hrv_metrics['HRV_pNN20'].values[0]) else hrv_metrics['HRV_pNN20'].values[0],\n",
    "                        }\n",
    "\n",
    "                        Lead_val.append(features)\n",
    "                        #features_df = pd.concat([features_df, pd.DataFrame(features, index=[0])], ignore_index=False)\n",
    "                    featurenet = extracted_data|Lead_val[0]|Lead_val[1]|Lead_val[2]\n",
    "                    if xyz_files:\n",
    "                        xyz_signals = []\n",
    "                        record = wfdb.rdrecord(xyz_files[i][:-4])\n",
    "                        leads = record.sig_name\n",
    "                        \n",
    "                        for i in range(1,len(leads[-3:])+1):\n",
    "                            xyz_signal = record.p_signal[:, -i]\n",
    "                            xyz_signals.append(xyz_signal)\n",
    "\n",
    "                        # Compute magnitude vector if all three axes are present\n",
    "                        if len(xyz_signals) == 3:\n",
    "                            vx, vy, vz = xyz_signals\n",
    "                            min_length = min(len(vx), len(vy), len(vz))\n",
    "                            vx, vy, vz = vx[:min_length], vy[:min_length], vz[:min_length]\n",
    "                            magnitude = np.sqrt(np.square(vx) + np.square(vy) + np.square(vz))\n",
    "                            sampling_rate = 1000\n",
    "                            # Preprocess ECG signal\n",
    "                        signals, info = nk.ecg_process(magnitude, sampling_rate=sampling_rate)\n",
    "\n",
    "                        # Example data\n",
    "                        # If ECG_R_Peaks is a binary array\n",
    "                        ECG_R_Peaks = np.array(signals['ECG_R_Peaks']) if 'ECG_R_Peaks' in signals else 0\n",
    "                        fs = 1000  # Sampling rate (Hz)\n",
    "\n",
    "                        # Step 1: Extract R-peak indices (if binary array)\n",
    "                        R_peak_indices = np.where(ECG_R_Peaks == 1)[0] if 'ECG_R_Peaks' in signals else 0\n",
    "\n",
    "                        # Step 2: Convert indices to timestamps (seconds)\n",
    "                        R_peak_timestamps = R_peak_indices / fs\n",
    "\n",
    "                        # Step 3: Calculate RR intervals (time difference between consecutive R-peaks)\n",
    "                        RR_intervals = np.diff(R_peak_timestamps) if 'ECG_R_Peaks' in signals else 0\n",
    "\n",
    "                        # Step 1: Extract indices of P onsets and R peaks (if binary arrays)\n",
    "                        ECG_P_Onset = np.array(signals['ECG_P_Onsets'])\n",
    "\n",
    "                        P_onset_indices = np.where(ECG_P_Onset == 1)[0]\n",
    "\n",
    "                        # Step 2: Convert indices to timestamps (seconds)\n",
    "                        P_onset_timestamps = P_onset_indices / fs\n",
    "                        R_peak_timestamps = R_peak_indices / fs\n",
    "\n",
    "                        # Step 3: Match each P onset to the nearest succeeding R peak\n",
    "                        PR_intervals = []\n",
    "                        for t_p in P_onset_timestamps:\n",
    "                            # Find the closest succeeding R peak\n",
    "                            succeeding_R_peaks = R_peak_timestamps[R_peak_timestamps > t_p]\n",
    "                            if len(succeeding_R_peaks) > 0:\n",
    "                                t_r = succeeding_R_peaks[0]  # Get the first (nearest) succeeding R peak\n",
    "                                PR_intervals.append(t_r - t_p)\n",
    "\n",
    "                        # Convert to numpy array for further processing\n",
    "                        PR_intervals = np.array(PR_intervals)\n",
    "\n",
    "                        ECG_Q_Peaks = np.array(signals['ECG_Q_Peaks'])\n",
    "                        \n",
    "\n",
    "                        ECG_T_Offsets = np.array(signals['ECG_T_Offsets'])\n",
    "\n",
    "                        # Step 1: Extract indices of Q peaks and T offsets (if binary arrays)\n",
    "                        Q_peak_indices = np.where(ECG_Q_Peaks == 1)[0]\n",
    "                        T_offset_indices = np.where(ECG_T_Offsets == 1)[0]\n",
    "\n",
    "                        # Step 2: Convert indices to timestamps (seconds)\n",
    "                        Q_peak_timestamps = Q_peak_indices / fs\n",
    "                        T_offset_timestamps = T_offset_indices / fs\n",
    "\n",
    "                        # Step 3: Match each Q peak to the nearest succeeding T offset\n",
    "                        QT_intervals = []\n",
    "                        for t_q in Q_peak_timestamps:\n",
    "                            # Find the closest succeeding T offset\n",
    "                            succeeding_T_offsets = T_offset_timestamps[T_offset_timestamps > t_q]\n",
    "                            if len(succeeding_T_offsets) > 0:\n",
    "                                t_t_offset = succeeding_T_offsets[0]  # Get the first (nearest) succeeding T offset\n",
    "                                QT_intervals.append(t_t_offset - t_q)\n",
    "\n",
    "                        # Convert to numpy array for further processing\n",
    "                        QT_intervals = np.array(QT_intervals)\n",
    "\n",
    "                        ECG_S_Peaks = np.array(signals['ECG_S_Peaks'])\n",
    "\n",
    "                        # Assuming you have the R-peaks detected\n",
    "                        R_peak_indices = np.where(signals['ECG_R_Peaks'] == 1)[0]  # Extract indices of R-peaks\n",
    "\n",
    "                        # Compute HRV metrics using the detected R-peaks\n",
    "                        hrv_metrics = nk.hrv_time(R_peak_indices, sampling_rate=1000)\n",
    "\n",
    "\n",
    "                        ECG_P_peaks = signals['ECG_P_Peaks']\n",
    "                        pp_intervals = np.diff(ECG_P_peaks)  # Convert to seconds\n",
    "\n",
    "                        s_peaks = signals['ECG_S_Peaks']\n",
    "                        t_onsets = signals['ECG_T_Onsets']\n",
    "\n",
    "                        # Calculate ST segment durations\n",
    "                        st_segments = np.array((t_onsets - s_peaks))/1000  # Convert to seconds\n",
    "\n",
    "                        # Extract the onsets and offsets of R-peaks\n",
    "                        r_onsets = signals['ECG_R_Onsets'].dropna().values\n",
    "                        r_offsets = signals['ECG_R_Offsets'].dropna().values\n",
    "\n",
    "                        # Ensure matching lengths\n",
    "                        if len(r_onsets) != len(r_offsets):\n",
    "                            raise ValueError(\"Mismatched lengths between R onsets and offsets.\")\n",
    "\n",
    "                        # Calculate QRS intervals (difference between offsets and onsets)\n",
    "                        qrs_intervals = (r_offsets - r_onsets) / fs\n",
    "\n",
    "                        features = {\n",
    "                            \"0_Mean_ECG_Rate\": np.nanmean(signals['ECG_Rate']) if 'ECG_Rate' in signals else 0,\n",
    "                            \"0_Mean_ECG_Quality\": np.nanmean(np.array(signals['ECG_Quality'])) if 'ECG_Quality' in signals else 0,\n",
    "                            \"0_Coeff_R_peaks\": 0 if 'ECG_R_Peaks' not in signals or np.isnan(np.nanmean(ECG_R_Peaks)) else np.nanstd(ECG_R_Peaks) / np.nanmean(ECG_R_Peaks),\n",
    "                            #\"0_Coeff_P_peaks\": 0 if np.isnan(np.nanmean(ECG_P_peaks)) else np.nanstd(ECG_P_peaks) / np.nanmean(ECG_P_peaks),\n",
    "                            #\"0_Coeff_Q_peaks\": 0 if np.isnan(np.nanmean(ECG_Q_Peaks)) else np.nanstd(ECG_Q_Peaks) / np.nanmean(ECG_Q_Peaks),\n",
    "                            #\"0_Coeff_S_peaks\": 0 if np.isnan(np.nanmean(ECG_S_Peaks)) else np.nanstd(ECG_S_Peaks) / np.nanmean(ECG_S_Peaks),\n",
    "                            #\"0_Coeff_T_peaks\": 0 if 'ECG_T_Peaks' not in signals or np.any(np.isnan(signals['ECG_T_Peaks'])) else np.nanstd(signals['ECG_T_Peaks']) / np.nanmean(signals['ECG_T_Peaks']),\n",
    "                            \"0_Mean_ECG_Phase_Atrial\": np.nanmean(signals['ECG_Phase_Atrial']) if 'ECG_Phase_Atrial' in signals else 0,\n",
    "                            \"0_Mean_ECG_Phase_Completion_Atrial\": np.nanmean(signals['ECG_Phase_Completion_Atrial']) if 'ECG_Phase_Completion_Atrial' in signals else 0,\n",
    "                            \"0_Mean_ECG_Phase_Ventricular\": np.nanmean(signals['ECG_Phase_Ventricular']) if 'ECG_Phase_Ventricular' in signals else 0,\n",
    "                            \"0_Mean_ECG_Phase_Completion_Ventricular\": np.nanmean(signals['ECG_Phase_Completion_Ventricular']) if 'ECG_Phase_Completion_Ventricular' in signals else 0,\n",
    "                            \"0_Coeff_RR_intervals\": 0 if np.isnan(np.nanmean(RR_intervals)) else np.nanstd(RR_intervals) / np.nanmean(RR_intervals),\n",
    "                            \"0_Coeff_PR_intervals\": 0 if np.isnan(np.nanmean(PR_intervals)) else np.nanstd(PR_intervals) / np.nanmean(PR_intervals),\n",
    "                            \"0_Coeff_QT_intervals\": 0 if np.isnan(np.nanmean(QT_intervals)) else np.nanstd(QT_intervals) / np.nanmean(QT_intervals),\n",
    "                            \"0_std_pp_intervals\": 0 if np.isnan(np.nanstd(pp_intervals)) else np.nanstd(pp_intervals),\n",
    "                            \"0_std_QRS_Interval\": 0 if np.isnan(np.nanstd(qrs_intervals)) else np.nanstd(qrs_intervals),\n",
    "                            \"0_HRV_SDNN\": 0 if np.isnan(hrv_metrics['HRV_SDNN'].values[0]) else hrv_metrics['HRV_SDNN'].values[0],\n",
    "                            \"0_HRV_RMSSD\": 0 if np.isnan(hrv_metrics['HRV_RMSSD'].values[0]) else hrv_metrics['HRV_RMSSD'].values[0],\n",
    "                            \"0_HRV_pNN20\": 0 if np.isnan(hrv_metrics['HRV_pNN20'].values[0]) else hrv_metrics['HRV_pNN20'].values[0],\n",
    "                        }\n",
    "                        feture = featurenet|features\n",
    "                        features_df = pd.concat([features_df, pd.DataFrame(feture, index=[0])], ignore_index=False)\n",
    "                \n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing patient {patient_folder}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = features_df['Reason for admission']\n",
    "features_df = features_df.drop(columns={'Reason for admission'})\n",
    "features_df['target'] = target\n",
    "features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export to CSV\n",
    "features_df.to_csv(output_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
